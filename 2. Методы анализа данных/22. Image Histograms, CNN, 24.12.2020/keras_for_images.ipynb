{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "indoor = 'indoor/'\n",
    "outdoor = 'outdoor/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_indoor = os.listdir(indoor)\n",
    "files_outdoor = os.listdir(outdoor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28106, 27216)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files_indoor), len(files_outdoor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_indoor = [indoor+i for i in files_indoor]\n",
    "f_outdoor = [outdoor+i for i in files_outdoor]\n",
    "indoor_images = skimage.io.imread_collection(f_indoor)\n",
    "outdoor_images = skimage.io.imread_collection(f_outdoor)\n",
    "assert len(indoor_images) == len(files_indoor)\n",
    "assert len(outdoor_images) == len(files_outdoor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 74, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indoor_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = [image.shape[0] for image in indoor_images]\n",
    "height = [image.shape[1] for image in indoor_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "width_outdoor = [image.shape[0] for image in outdoor_images]\n",
    "height_outdoor = [image.shape[1] for image in outdoor_images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. `Resize` изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 28106/28106 [05:26<00:00, 86.06it/s]\n"
     ]
    }
   ],
   "source": [
    "transofrmed_image_indoor = [skimage.transform.resize(i, (32, 32)) for i in tqdm(indoor_images)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transofrmed_image_indoor_2 = np.array(transofrmed_image_indoor, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 27216/27216 [03:38<00:00, 124.63it/s]\n"
     ]
    }
   ],
   "source": [
    "transofrmed_image_outdoor = [skimage.transform.resize(i, (32, 32)) for i in tqdm(outdoor_images)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transofrmed_image_outdoor_2 = np.array(transofrmed_image_outdoor, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28106, 32, 32, 3), (27216, 32, 32, 3))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transofrmed_image_indoor_2.shape, transofrmed_image_outdoor_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((transofrmed_image_indoor_2, transofrmed_image_outdoor_2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55322, 32, 32, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.r_[np.ones(len(files_indoor)), np.zeros(len(files_outdoor))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55322, 32, 32, 3), (55322,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `2`. Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "y_categorical = keras.utils.to_categorical(y, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 16, 16, 32)        2432      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 6, 6, 32)          25632     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               147968    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 177,058\n",
      "Trainable params: 177,058\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Conv2D(32, (5, 5), strides = (2,2), padding='same',\n",
    "                 input_shape=X_train.shape[1:]))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(Conv2D(32, (5, 5), strides = (2,2)))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_1.add(Dropout(0.25))\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(512))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(Dropout(0.5))\n",
    "model_1.add(Dense(num_classes))\n",
    "model_1.add(Activation('softmax'))\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1211/1211 [==============================] - 97s 75ms/step - loss: 0.4260 - accuracy: 0.7972 - val_loss: 0.2623 - val_accuracy: 0.8937\n",
      "Epoch 2/15\n",
      "1211/1211 [==============================] - 95s 79ms/step - loss: 0.2646 - accuracy: 0.8900 - val_loss: 0.2218 - val_accuracy: 0.9144\n",
      "Epoch 3/15\n",
      "1211/1211 [==============================] - 95s 79ms/step - loss: 0.2393 - accuracy: 0.9070 - val_loss: 0.2381 - val_accuracy: 0.9087\n",
      "Epoch 4/15\n",
      "1211/1211 [==============================] - 94s 78ms/step - loss: 0.2218 - accuracy: 0.9132 - val_loss: 0.2211 - val_accuracy: 0.9168\n",
      "Epoch 5/15\n",
      "1211/1211 [==============================] - 94s 78ms/step - loss: 0.2128 - accuracy: 0.9180 - val_loss: 0.2651 - val_accuracy: 0.8915\n",
      "Epoch 6/15\n",
      "1211/1211 [==============================] - 92s 76ms/step - loss: 0.2018 - accuracy: 0.9239 - val_loss: 0.2108 - val_accuracy: 0.9259\n",
      "Epoch 7/15\n",
      "1211/1211 [==============================] - 91s 75ms/step - loss: 0.1964 - accuracy: 0.9247 - val_loss: 0.2473 - val_accuracy: 0.9094acy: 0.9 - ETA - ETA: 3s - l - ETA: 2s - loss: 0 - ETA\n",
      "Epoch 8/15\n",
      "1211/1211 [==============================] - 96s 80ms/step - loss: 0.1967 - accuracy: 0.9281 - val_loss: 0.1950 - val_accuracy: 0.9312\n",
      "Epoch 9/15\n",
      "1211/1211 [==============================] - 103s 85ms/step - loss: 0.1826 - accuracy: 0.9314 - val_loss: 0.1943 - val_accuracy: 0.9290\n",
      "Epoch 10/15\n",
      "1211/1211 [==============================] - 98s 81ms/step - loss: 0.1800 - accuracy: 0.9329 - val_loss: 0.2295 - val_accuracy: 0.9172\n",
      "Epoch 11/15\n",
      "1211/1211 [==============================] - 108s 89ms/step - loss: 0.1699 - accuracy: 0.9367 - val_loss: 0.2486 - val_accuracy: 0.9064\n",
      "Epoch 12/15\n",
      "1211/1211 [==============================] - 96s 79ms/step - loss: 0.1732 - accuracy: 0.9361 - val_loss: 0.1868 - val_accuracy: 0.9355\n",
      "Epoch 13/15\n",
      "1211/1211 [==============================] - 96s 80ms/step - loss: 0.1670 - accuracy: 0.9376 - val_loss: 0.1898 - val_accuracy: 0.9376\n",
      "Epoch 14/15\n",
      "1211/1211 [==============================] - 90s 75ms/step - loss: 0.1604 - accuracy: 0.9422 - val_loss: 0.2120 - val_accuracy: 0.9320\n",
      "Epoch 15/15\n",
      "1211/1211 [==============================] - 100s 82ms/step - loss: 0.1584 - accuracy: 0.9435 - val_loss: 0.2030 - val_accuracy: 0.9302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fe8db797f0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "opt = keras.optimizers.RMSprop(lr=0.0005, decay=1e-6)\n",
    "model_1.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_1.fit(X_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=15,\n",
    "              validation_data=(X_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили прирост в качестве: `accuracy` $\\approx 93\\%$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
