\documentclass[%
10pt, %
final, % 
oneside, % 
onecolumn, %  
centertags]{article} % относится к классу article и размер шрифта 12 пунктовб, {article: статья, report: отчеты и диссертации, book: книга, letter: письмо}

% ------ page construction 

\topmargin= -30pt % насколько сверху будет страница
\textheight= 650pt

% ------ Пакеты расширения

\usepackage[utf8]{inputenc} % задает кодировку, utf-8 кодировка, включающая в себя знаки почти всех языков мира
\usepackage[english, russian]{babel} % подключает необходимые языки, основным языком является английский
\selectlanguage{russian} % настройки будут на английском, но писать будет на русском

\usepackage{euscript}
\usepackage{supertabular}

\usepackage[colorlinks=true,linkcolor=black,unicode=true,urlcolor = blue]{hyperref} %hyperef
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage[pdftex]{graphicx} % для графики и изображений
\graphicspath{ {./images/} } % задаю начальный каталог, их может быть несколько, откуда буду добавлять картинки в файл


\usepackage{alltt} % текст интерпретируется буквально
\usepackage{amsthm, amssymb, amsmath, amsfonts} % математический пакет, математические шрифты
\usepackage{textcomp}
\usepackage[noend]{algorithmic}
\usepackage[ruled]{algorithm}
\usepackage{lipsum}
\usepackage{indentfirst}
\usepackage{babel}
\usepackage{pgfplots}
\usepackage{setspace}


\linespread{1.2} 
\setlength{\parindent}{2.4em}
\setlength{\parskip}{0.1em}

\pgfplotsset{compat=1.9}
\pgfplotsset{model/.style = {blue, samples = 100}} 
\pgfplotsset{experiment/.style = {red}}

\binoppenalty=10000

% ----- Теоремы и определения
\theoremstyle{plain}

\newtheorem{theorem}{Теорема}[section] % theorem

\theoremstyle{definition}
\newtheorem{definition}{Определение}[subsection] % определение

\theoremstyle{remark}
\newtheorem{remark}{Замечание}[section] % замечание

\newtheorem{corollary}{Следствие} %следствие

\newtheorem{proposition}{Утверждение} % утверждение

\newtheorem{example}{Пример} % пример

\newtheorem{lemma}{Лемма}[section] %lemma

\renewcommand*{\proofname}{Proof}


\begin{document}

\begin{titlepage} 
\begin{center}
\textbf{}\\[10.0cm]
\textbf{\LARGE Методы анализа данных}\\[0.5cm]
\textbf{\Large Александр Широков ПМ-1701} \\[0.2cm]


\begin{center} \large
{Преподаватель:} \\[0.5cm]
\textsc {Ивахненко Дарья Александровна}\\
\end{center}

\vfill 



{\large {Санкт-Петербург}} \par
{\large {2020 г., 7 семестр}}
\end{center} 
\end{titlepage}

% Table of contents
\begin{thebibliography}{3}
  \bibitem{A}
\end{thebibliography}
\tableofcontents
\newpage

\section{01.09.2020}

\subsection{Задача обучения по предедентам}

Пусть $X$ - множество объектов, а $Y$ - множество ответов. $y: X \to Y$ - неизвестная зависимость.

Дано: $\{x_1,\ldots,x_l\} \subset X$ - обучающая выборка, а $y_i = y(x_i), i = 1, \ldots,l$ - известные ответы.

Требуется найти $a: X \to Y$ - алгоритм, решающую функцию, приближающую $y$ на всем множестве $X$.

\subsection{Типы задач}

\textbf{Задачи восстановления регрессии:}

\begin{itemize}
	\item $Y = \mathbb{R}$ - вся числовая ось:
	\begin{itemize}
		\item определение температуры воздуха метеорологического поля
		\item оценка влияния факторов потребления
	\end{itemize}
	\item $Y \in [0;+\infty)$:
	\begin{itemize}
		\item задачи медицинской диагностики: прогнозирование ожидаемого время действия препарата
		\item задачи кредитного скоринга: определение величины кредитного лимита
		\item определение расхода топлива по техническим характеристикам
	\end{itemize}
	\item $Y \in [0,1,\ldots,+\infty)$ - счетная целевая переменная
\end{itemize}

\textbf{Задача классификации:}

\begin{itemize}
	\item $Y = \{-1,+1\}$ - классификация на два класса:
	\begin{itemize}
		\item задачи кредитного скоринга: решение о выдаче кредита
		\item предсказание оттока клиентов
	\end{itemize}

	\item $Y = \{1,\ldots,K\}$ - классификация на $K$ непересекающихся классов:
	\begin{itemize}
		\item задачи медицинской диагностики: определение диагноза
		\item распознавание символов
		\item определение жанра
	\end{itemize}

	\item $Y = \{0,1\}^K$ - на $K$ классов, которые могут пересекаться:
	\begin{itemize}
		\item определение ключевых слов для оптимизации поиска
		\item определение присутствующих на фото объектов
	\end{itemize}
\end{itemize}

\textbf{Типы признаков}

\begin{itemize}
	\item $D_j = \{0,1\}$ - бинарный признак $f_j$:
	\begin{itemize}
		\item пол
		\item является ли..?
	\end{itemize}
	\item $|D_j| < \infty$ - номинальный признак $f_j$:
	\begin{itemize}
		\item город
		\item цвет
	\end{itemize}
	\item $|D_j| < \infty$, $D_j$ - упорядочено - порядковый признак $f_j$:
	\begin{itemize}
		\item уровень холестерина (ниже нормы, норма, выше нормы)
	\end{itemize}
	\item $D_j = \textbf{R}$ - количественный признак $f_j$:
	\begin{itemize}
		\item длина и ширина объекта
	\end{itemize}
\end{itemize}


\subsection{08.09.2020}

\subsubsection{Задача бинарной классификации}

Выведем функцию связи через биномиальное распределение через задачу классификации:

$y \in \{0,1\}$ 
$$g^{-1}(p) = \overline{\theta}^T \overline{X}$$
$$f(y) = e^{\frac{y\alpha-c(\alpha)}{\varphi}+h(y,\varphi)}$$

Плотность биномиального распределения:
$$f(y) = p^y(1-p)^{1-y} = exp(y\log p + (1-y)\log(1-p)) = exp(y\log\frac{p}{1-p}+\log(1-p)\equiv c(\alpha)$$
$$\alpha  = \log \frac{p}{1-p} = g(p) = \overline{\theta}^T \overline{X}$$
$$\frac{p}{1-p} = e^{\overline{\theta}^T \overline{X}}$$
$$p = \sigma\left(\overline{\theta}^T \overline{X}\right) = \frac{1}{1+e^{-\overline{\theta}^T \overline{X}}}$$

Осталось получить функционал качества для задачи классификации. Функция называется \textsc{логистической сигмоидой}. Данная функция преобразует линейную комбинацию в интервал $[0,1]$. Дальнейшее значение целевой переменной мы будем предсказывать в качестве:
$$\hat{y} = \sigma\left(\overline{\theta}^T \overline{X}\right)$$

Функционал качества найдём через метод максимального правдоподобия:
$$p(x,y,p) = \prod\limits_{i=1}^l p_i^{y_i}(1-p_i)^{1-y_i} \xrightarrow[\theta]{}\max $$
$$\sum\limits_{i=1}^l y_i \log p_i + (1-y_i)\log(1-p_i)  \xrightarrow[\theta]{}\max$$

Функция потерь называется \textsc{LogLoss}:
$$LogLoss = L(x_i) = y_i \log p_i - (1-y_i)\log p_i  \xrightarrow[\theta]{}\min, p_i = \sigma(x_i)$$

Если мы правильно предсказываем отношение принадлежности класса к $1$, то функция потерь будет равна нулю, если правильно предсказываем $0$ правильно, то тоже $0$, а если $1$ - правильный ответ, а $0$ - нет, то ошибка будет $+\infty$, и ошибку ограничивают значениями $100$, чтобы ошибка не уходила далеко.
$$p = \sigma\left(\overline{\theta}^T \overline{X}\right) \in [0,1]$$
$$L = -y\log p - (1-y)\log(1-p)$$

\subsubsection{Задача многоклассовой классификации}

\begin{definition}
	\textsc{Categorical Distribution}: $y \in \{1,2,\ldots,K\}$
	$$f(y) = \prod\limits_{i=1}^K p_i^{y_i}$$
\end{definition}

Выведем функцию связи через \textsc{Categorical Distribution}:
$$f(y) = \prod\limits_{i=1}^K p_i^{y_i} = \exp (\log \prod\limits_{i=1}^K p_i^{y_i}) = \exp (\sum\limits_{i=1}^K y_i \log p_i)$$

Рассмотрим определенный $y_i$:
$$f(y) = \exp(y_1\log p_1 + y_2\log p_2 + \ldots + y_K\log p_K)$$
$$\sum\limits y_i = 1$$
$$\sum\limits p_i = 1$$

Так как $y_i$ имеет принадлежность определенному классу и может быть равен только одной единице в векторе:
$$\{0,0,1,0\}$$
а сумма вероятностей по определению. Тогда:
$$f(y) = \exp(y_1\log p_1 + \ldots + \left(1-\sum\limits_{i}^{K-1}y_i\right)\log p_k) = $$
$$ = \exp\left(y_1 \log \frac{p_1}{p_k} + y_2 \log \frac{p_2}{p_k} + \ldots + \log p_k \right)$$

$X$ для всех одинаковый, а $y$ разные. Для определения $y_i$ нам необходимо определить $\alpha_i$:
$$\alpha_i = \log \frac{p_i}{p_k} = \overline{\theta}^T \overline{X}$$
$$\frac{p_i}{p_k} = e^{\overline{\theta}^T \overline{X}}$$
$$\sum\limits_i^K e^{\overline{\theta_i}^T \overline{X}} = \frac{\sum\limits+i p_i}{p_k} = \frac{1}{p_k}$$
$$p_k= \frac{1}{\sum\limits_i^K e^{\overline{\theta_i}^T \overline{X}}}$$
$$\frac{p_i}{p_k} = e^{\overline{\theta_i}^T \overline{X}}$$
$$p_i = \frac{e^{\overline{\theta_i}^T \overline{X}}}{\sum\limits_{i=1}^K e^{\overline{\theta_i}^T \overline{X}}}$$

Данная функция называется функцией \textsc{SoftMax}.

Функционал качества мы можем легко получить:
$$L(x,y,p) = \prod\limits_{i=1}^l \prod\limits_{j=1}^K p_{ij}^{y_ij} \to \max$$
где $i$ - $i$-ый объект, а $j$ - принадлежность $j$-му классу.

Тогда функция потери для каждого класса:
$$-\sum\limits_{j=1}^K y_j \log p_j \to \min$$
и данная функция называется \textsc{кросс-энтропией}.

Итого:
\begin{itemize}
	\item $y \in \{0,1\}$:
	$$Q = -\left(\sum\limits_{i=1}^l y_i \log \sigma_i + (1-y_i) \log(1-\sigma_i)\right) \xrightarrow[\theta]{\min}$$
	\item $y \in \{1,2,\ldots,K\}$:
	$$Q = - \sum\limits_{i=1}^{l} y_{ij}\log G_{ij}$$
	где $y$ представляется вектором и матрица весов:
	$$\Theta = \begin{bmatrix}
		\theta_{11} & \theta_{12} & \ldots & \theta_{1N}\\
		\ldots & \ldots & \ldots & \ldots \\
		\theta_{K1} & \ldots & \ldots & \theta_{KN}
	\end{bmatrix}$$
\end{itemize}

\subsubsection{Принадлежность многим классам}

$$f(y) = \prod\limits_{i=1}^K p_i^{y_i}$$
$$f(y) = p^y(1-p)^{1-y}$$

Объединение двух распределений будет выглядеть следующим образом:
$$\prod\limits_{i=1}^K p_i^{y_i}(1-p_i)^{1-y_i} \qquad p_i = G(\overline{\theta_i}^T \overline{X})$$

Матрица весов размерности $K \times M$
Необходимо:
\begin{itemize}
	\item Вывести функционал качества
	$$f(y) = \exp \left(\log \prod\limits_{i=1}^K p_i^{y_i}(1-p_i)^{1-y_i}\right) = \exp\left(\sum\limits_{i=1}^K y_i \log p_i + \sum\limits_{i=1}^K (1-y_i) \log (1-p_i)\right)$$
	$$Q = \prod\limits_{i=1}^l \prod\limits_{j=1}^K \sigma_{ij}^{y_{ij}}(1-\sigma_{ij})^{1-y_{ij}} \to \max$$
	$$Q = -\sum\limits_{i=1}^l \sum\limits_{j=1}^K \left(y_{ij}\log \sigma_{ij}+(1-y_{ij})\log (1-\sigma_{ij})\right)\xrightarrow[\theta]{\min}$$
	$$L = - \sum\limits_{j=1}^K \left(y_{j}\log \sigma_{j}+(1-y_{j})\log (1-\sigma_{j})\right)\xrightarrow[\theta]{\min}$$
	\item Градиент функции потерь
	$$\frac{\partial L}{\partial \theta_{KM}} = \frac{y_k}{\sigma_{K}} \cdot \sigma_k(1-\sigma_K)x_{KM} - (1-y_k)\frac{1}{1-\sigma_k}\sigma_k (1-\sigma_k) x_{KM} $$
	$$ = y_k(1-\sigma_k)x_{KM} - (1-y_k)\sigma_k x_{KM} = x_{KM}(y_k-y_k\sigma_k-\sigma_k+\sigma_k y_k) = x_{KM}(y_k-\sigma_k)$$
	так как
	$$\sigma_k = \frac{1}{1+e^{-\overline{\theta_k}^T \overline{x}}}$$
	$$\sigma(z)' = \left(\frac{1}{1+e^{-z}}\right)' = - \frac{e^{-z}(-1)}{(1+e^{-z})^2} = \sigma(z) \cdot (1-\sigma(z))$$

\end{itemize}

\subsection{Методы обработки текстов}





\end{document}