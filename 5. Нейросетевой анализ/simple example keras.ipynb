{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Загрузим обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  87, 138,\n",
       "        170, 253, 201, 244, 212, 222, 138,  86,  22,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  95, 253, 252,\n",
       "        252, 252, 252, 253, 252, 252, 252, 252, 245,  80,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  68, 246, 205,  69,\n",
       "         69,  69,  69,  69,  69,  69,  69, 205, 253, 240,  50,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 187, 252, 218,  34,\n",
       "          0,   0,   0,   0,   0,   0,   0, 116, 253, 252,  69,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 116, 248, 252, 253,  92,\n",
       "          0,   0,   0,   0,   0,   0,  95, 230, 253, 157,   6,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 116, 249, 253, 189,  42,\n",
       "          0,   0,   0,   0,  36, 170, 253, 243, 158,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 133, 252, 245, 140,\n",
       "         34,   0,   0,  57, 219, 252, 235,  60,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  25, 205, 253, 252,\n",
       "        234, 184, 184, 253, 240, 100,  44,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  21, 161, 219,\n",
       "        252, 252, 252, 234,  37,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 203,\n",
       "        252, 252, 252, 251, 135,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   9,  76, 255, 253,\n",
       "        205, 168, 220, 255, 253, 137,   5,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 114, 252, 249, 132,\n",
       "         25,   0,   0, 180, 252, 252,  45,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  51, 220, 252, 199,   0,\n",
       "          0,   0,   0,  38, 186, 252, 154,   7,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 184, 252, 252,  21,   0,\n",
       "          0,   0,   0,   0,  67, 252, 252,  22,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 184, 252, 200,   0,   0,\n",
       "          0,   0,   0,   0,  47, 252, 252,  22,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 185, 253, 201,   0,   0,\n",
       "          0,   0,   0,   3, 118, 253, 245,  21,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 163, 252, 252,   0,   0,\n",
       "          0,   0,   0,  97, 252, 252,  87,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  51, 240, 252, 123,  70,\n",
       "         70, 112, 184, 222, 252, 170,  13,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 165, 252, 253, 252,\n",
       "        252, 252, 252, 245, 139,  13,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   9,  75, 253, 252,\n",
       "        221, 137, 137,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[333]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[333]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28775f4c0b8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[333], cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) train samples\n",
      "(10000, 28, 28) test samples\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, 'train samples')\n",
    "print(x_test.shape, 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для распознавания рукописных цифр будем использовать полносвязную нейронную сеть, где каждый нейрон входного слоя характеризует один пиксель исходного изображения. При этом сами изображения представляют собой матрицу чисел, поэтому для дальнейшей работы необходимо выполнить преобразования над данными.\n",
    "\n",
    "С помощью функции `reshape` преобразуйте каждую матрицу в вектор длины 28*28 (размер исходных изображений)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку мы будем использовать градиентные методы обучения, необходимо также нормализовать данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(len(x_train), 28*28)\n",
    "x_test = x_test.reshape(len(x_test), 28*28)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данный момент значение целевой переменной каждого изображения представляет собой цифру от 0 до 9. Для решения задачи многоклассовой классификации можно использовать функцию softmax. Её выход при этом - вектор вероятностей принадлежности к каждому из классов. Таким образом, возникает необходимость преобразовать `y_train` и `y_test`.\n",
    "\n",
    "Для этих целей в `keras` доступна функция `keras.utils.to_categorical`, принимающая на вход исходный вектор значений и количество классов. Примените данную функцию к  `y_train` и  `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "y_train[333]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно приступать к обучению сети. Будем использовать следующую архитектуру:\n",
    "- на вход подается 784 значения;\n",
    "- далее идет полносвязный слой с 256 нейронами и функцией активации `relu`;\n",
    "- для повышения обобщающей способности модели добавим `Dropout(0.2)`, где `0.2` - вероятность отключения каждого из нейронов слоя;\n",
    "- далее еще один полносвязный слой с 256 нейронами и функцией активации `relu`;\n",
    "- последний слой - выход сети - полносвязный слой с числом нейронов, равным числу классов и функцией активации `softmax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Dense(64, activation='relu', input_shape=(784,)))\n",
    "model_1.add(Dropout(0.2))\n",
    "model_1.add(Dense(64, activation='relu'))\n",
    "model_1.add(Dropout(0.2))\n",
    "model_1.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите полученную модель на обучающей выборке. Для обучения:\n",
    "- выберите нужную функцию потерь: https://keras.io/losses/; \n",
    "- optimizer - RMSProp: https://keras.io/optimizers/; \n",
    "- размер мини-батча - 128;\n",
    "- число эпох - 10;\n",
    "- на каждом шаге выводите значение `accuracy` как на обучающей, так и на тестовой выборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = .001\n",
    "model_1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0706 01:34:32.467166  4796 deprecation.py:323] From c:\\users\\shiro\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\optimizers.py:279: BaseResourceVariable.constraint (from tensorflow.python.ops.resource_variable_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Apply a constraint manually following the optimizer update step.\n",
      "W0706 01:34:34.092665  4796 deprecation_wrapper.py:118] From c:\\users\\shiro\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.5131 - accuracy: 0.8462 - val_loss: 0.2046 - val_accuracy: 0.9372\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2524 - accuracy: 0.9255 - val_loss: 0.1616 - val_accuracy: 0.9531\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1998 - accuracy: 0.9413 - val_loss: 0.1379 - val_accuracy: 0.9594\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1752 - accuracy: 0.9476 - val_loss: 0.1244 - val_accuracy: 0.9650\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.1555 - accuracy: 0.9542 - val_loss: 0.1160 - val_accuracy: 0.9662\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.1456 - accuracy: 0.9575 - val_loss: 0.1078 - val_accuracy: 0.9697\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.1361 - accuracy: 0.9592 - val_loss: 0.1081 - val_accuracy: 0.9695\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.1278 - accuracy: 0.9635 - val_loss: 0.1043 - val_accuracy: 0.9717\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.1204 - accuracy: 0.9647 - val_loss: 0.1071 - val_accuracy: 0.9704\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1155 - accuracy: 0.9656 - val_loss: 0.1062 - val_accuracy: 0.9707\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1139 - accuracy: 0.9669 - val_loss: 0.0969 - val_accuracy: 0.9734\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1086 - accuracy: 0.9677 - val_loss: 0.1014 - val_accuracy: 0.9738\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1042 - accuracy: 0.9698 - val_loss: 0.1049 - val_accuracy: 0.9723\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1029 - accuracy: 0.9698 - val_loss: 0.1015 - val_accuracy: 0.9737\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0998 - accuracy: 0.9706 - val_loss: 0.1047 - val_accuracy: 0.9733\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.0989 - accuracy: 0.9707 - val_loss: 0.1031 - val_accuracy: 0.9734\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0948 - accuracy: 0.9721 - val_loss: 0.0988 - val_accuracy: 0.9753\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0936 - accuracy: 0.9724 - val_loss: 0.1042 - val_accuracy: 0.9743\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.0910 - accuracy: 0.9729 - val_loss: 0.1059 - val_accuracy: 0.9743\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0922 - accuracy: 0.9725 - val_loss: 0.1158 - val_accuracy: 0.9733\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0894 - accuracy: 0.9738 - val_loss: 0.1120 - val_accuracy: 0.9731\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.0910 - accuracy: 0.9736 - val_loss: 0.1045 - val_accuracy: 0.9749\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0895 - accuracy: 0.9740 - val_loss: 0.1129 - val_accuracy: 0.9755\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.0846 - accuracy: 0.9753 - val_loss: 0.1074 - val_accuracy: 0.9749\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0865 - accuracy: 0.9744 - val_loss: 0.1107 - val_accuracy: 0.9748\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0838 - accuracy: 0.9754 - val_loss: 0.1079 - val_accuracy: 0.9744\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0803 - accuracy: 0.9753 - val_loss: 0.1128 - val_accuracy: 0.9749\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.0840 - accuracy: 0.9758 - val_loss: 0.1038 - val_accuracy: 0.9746\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.0818 - accuracy: 0.9757 - val_loss: 0.1155 - val_accuracy: 0.9739\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.0840 - accuracy: 0.9756 - val_loss: 0.1152 - val_accuracy: 0.9763\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 30\n",
    "history = model_1.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.11518295423117525\n",
      "Test accuracy: 0.9763000011444092\n"
     ]
    }
   ],
   "source": [
    "score = model_1.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(Conv2D(32, (5, 5), strides = (2,2), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Conv2D(32, (5, 5), strides = (2,2)))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_2.add(Dropout(0.25))\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(512))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Dense(num_classes))\n",
    "model_2.add(Activation('softmax'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
